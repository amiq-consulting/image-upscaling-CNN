{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "import pynq.lib.dma\n",
    "# Load the overlay\n",
    "overlay = Overlay('/home/xilinx/pynq/overlays/FSRCNN/FSRCNN.bit')\n",
    "#overlay?\n",
    "# Load the DMA\n",
    "dma = overlay.DMA \n",
    "# Load FSRCNN IP\n",
    "FSRCNN_ip = overlay.FSRCNN_0\n",
    "#test_ip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image size:  (64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "in_img = cv2.imread('input_image_64x64_butterfly.jpeg')\n",
    "height, width, nr_of_channels = in_img.shape\n",
    "print('Input image size: ',in_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale factor:  2\n"
     ]
    }
   ],
   "source": [
    "#write the constants to the respective addresses\n",
    "scale_factor = 2\n",
    "FSRCNN_ip.write(0x10,height)                            \n",
    "FSRCNN_ip.write(0x18,width)  \n",
    "FSRCNN_ip.write(0x20,scale_factor)                                                  \n",
    "#verif_input_width = FSRCNN_ip.read(0x18)\n",
    "verif_scale_factor = FSRCNN_ip.read(0x20)\n",
    "print('Scale factor: ',verif_scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   pynq import allocate\n",
    "import time\n",
    "out_height = scale_factor*height\n",
    "out_width  = scale_factor*width\n",
    "size_stream_in    = height*width\n",
    "size_stream_out   = out_height*out_width\n",
    "red_channel_in    = allocate(shape=(size_stream_in,1),  dtype=np.uint32)\n",
    "red_channel_out   = allocate(shape=(size_stream_out,1), dtype=np.uint32)\n",
    "green_channel_in  = allocate(shape=(size_stream_in,1),  dtype=np.uint32)\n",
    "green_channel_out = allocate(shape=(size_stream_out,1), dtype=np.uint32)\n",
    "blue_channel_in   = allocate(shape=(size_stream_in,1),  dtype=np.uint32)\n",
    "blue_channel_out  = allocate(shape=(size_stream_out,1), dtype=np.uint32)\n",
    "k= 0\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "            red_channel_in[k,0]   = in_img[i,j,0]\n",
    "            green_channel_in[k,0] = in_img[i,j,1]\n",
    "            blue_channel_in[k,0]  = in_img[i,j,2]\n",
    "            k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import suppress\n",
    "start_time = time.time()\n",
    "# Trigger the DMA transfer and wait for the result\n",
    "dma.sendchannel.transfer(red_channel_in)  #python - dma - accelerator PYNQ\n",
    "dma.recvchannel.transfer(red_channel_out) #PYNQ accelerator - dma - python\n",
    "dma.sendchannel.wait()                    #makes sure that does not move on until the transfer is effectuated\n",
    "stop_time = time.time()\n",
    "with suppress(RuntimeError): \n",
    "    dma.recvchannel.wait()\n",
    "red_channel_hw_exec_time = stop_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/pynq/overlays/FSRCNN/FSRCNN.bit')\n",
    "# Load the DMA\n",
    "dma = overlay.DMA \n",
    "# Load FSRCNN IP\n",
    "FSRCNN_ip = overlay.FSRCNN_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Trigger the DMA transfer and wait for the result\n",
    "dma.sendchannel.transfer(green_channel_in)  #python - dma - accelerator PYNQ\n",
    "dma.recvchannel.transfer(green_channel_out) #PYNQ accelerator - dma - python\n",
    "dma.sendchannel.wait()                      #makes sure that does not move on until the transfer is effectuated\n",
    "stop_time = time.time()\n",
    "with suppress(RuntimeError):\n",
    "    dma.recvchannel.wait()\n",
    "green_channel_hw_exec_time = stop_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay('/home/xilinx/pynq/overlays/FSRCNN/FSRCNN.bit')\n",
    "# Load the DMA\n",
    "dma = overlay.DMA \n",
    "# Load FSRCNN IP\n",
    "FSRCNN_ip = overlay.FSRCNN_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Trigger the DMA transfer and wait for the result\n",
    "dma.sendchannel.transfer(blue_channel_in)  #python - dma - accelerator PYNQ\n",
    "dma.recvchannel.transfer(blue_channel_out) #PYNQ accelerator - dma - python\n",
    "dma.sendchannel.wait()                     #makes sure that does not move on until the transfer is effectuated\n",
    "stop_time = time.time()\n",
    "with suppress(RuntimeError):\n",
    "    dma.recvchannel.wait()\n",
    "blue_channel_hw_exec_time = stop_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardware FSRCNN execution time:  7.0588579177856445\n",
      "Hardware acceleration factor (FPGA accelerator vs C/C++ CPU version):  23.09155417185857\n",
      "Hardware acceleration factor (FPGA accelerator vs Python CPU version):  38.78814436966182\n"
     ]
    }
   ],
   "source": [
    "CPU_C_exec_time = 163\n",
    "CPU_Python_exec_time = 273.80\n",
    "hw_exec_time = red_channel_hw_exec_time + green_channel_hw_exec_time + blue_channel_hw_exec_time\n",
    "print('Hardware FSRCNN execution time: ',hw_exec_time)\n",
    "print('Hardware acceleration factor (FPGA accelerator vs C/C++ CPU version): ',CPU_C_exec_time / hw_exec_time)\n",
    "print('Hardware acceleration factor (FPGA accelerator vs Python CPU version): ',CPU_Python_exec_time / hw_exec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output image size:  (128, 128, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_img = np.zeros((out_height, out_width, nr_of_channels))\n",
    "print('Output image size: ',out_img.shape)\n",
    "k = 0\n",
    "for i in range(out_height):\n",
    "    for j in range(out_width):\n",
    "            red_channel_bin = np.binary_repr(red_channel_out[k,0], width = 32)\n",
    "            out_img[i,j,0] = int(str(red_channel_bin[24:32]), 2)\n",
    "            green_channel_bin = np.binary_repr(green_channel_out[k,0], width = 32)\n",
    "            out_img[i,j,1] = int(str(green_channel_bin[24:32]), 2)\n",
    "            blue_channel_bin = np.binary_repr(blue_channel_out[k,0], width = 32)\n",
    "            out_img[i,j,2] = int(str(blue_channel_bin[24:32]), 2)\n",
    "            k = k+1\n",
    "cv2.imwrite('output_image_128x128_butterfly.jpeg', out_img)\n",
    "#cv2.imshow('output_image',out_img)\n",
    "#cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
